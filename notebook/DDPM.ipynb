{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinearity(x):\n",
    "    return F.silu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, temb, name):\n",
    "    return nn.GroupNorm(num_groups=32, num_channels=x.shape[1], eps=1e-6, affine=True)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, num_units, kernel_size=3, stride=1, init_scale=1.0):\n",
    "    conv = weight_norm(nn.Conv2d(x.shape[1], num_units, kernel_size, stride, padding=kernel_size // 2))\n",
    "    nn.init.kaiming_normal_(conv.weight, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    conv.weight.data *= init_scale\n",
    "    return conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(x, with_conv):\n",
    "    B, C, H, W = x.shape\n",
    "    x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "    if with_conv:\n",
    "        x = conv2d(x, num_units=C, kernel_size=3, stride=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(x, with_conv):\n",
    "    if with_conv:\n",
    "        x = conv2d(x, num_units=x.shape[1], kernel_size=3, stride=2)\n",
    "    else:\n",
    "        x = F.avg_pool2d(x, kernel_size=2, stride=2, padding=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin(x, num_units):\n",
    "    B, C, H, W = x.shape\n",
    "    return weight_norm(nn.Conv2d(C, num_units, kernel_size=1, stride=1, padding=0))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(x, temb, out_ch=None, conv_shortcut=False, dropout=0.0):\n",
    "    B, C, H, W = x.shape\n",
    "    if out_ch is None:\n",
    "        out_ch = C\n",
    "\n",
    "    h = x\n",
    "    h = nonlinearity(normalize(h, temb, name='norm1'))\n",
    "    h = conv2d(h, num_units=out_ch)\n",
    "    h = h + nn.linear(nonlinearity(temb), out_ch)[:, :, None, None]\n",
    "\n",
    "    h = nonlinearity(normalize(h, temb, name='norm2'))\n",
    "    h = F.dropout(h, p=dropout, training=True)\n",
    "    h = conv2d(h, num_units=out_ch, init_scale=0.)\n",
    "\n",
    "    if C != out_ch:\n",
    "        if conv_shortcut:\n",
    "            x = conv2d(x, num_units=out_ch)\n",
    "        else:\n",
    "            x = nin(x, out_ch)\n",
    "\n",
    "    return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(x, num_units):\n",
    "    return weight_norm(nn.Linear(x.shape[-1], num_units))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_block(x, temb):\n",
    "    B, C, H, W = x.shape\n",
    "    h = normalize(x, temb=temb, name='norm')\n",
    "    q = nin(h, C)\n",
    "    k = nin(h, C)\n",
    "    v = nin(h, C)\n",
    "\n",
    "    w = torch.einsum('bchw,bCHW->bhwHW', q, k) * (C ** -0.5)\n",
    "    w = w.view(B, H, W, H * W)\n",
    "    w = F.softmax(w, dim=-1)\n",
    "    w = w.view(B, H, W, H, W)\n",
    "\n",
    "    h = torch.einsum('bhwHW,bHWc->bhwc', w, v)\n",
    "    h = nin(h, C)\n",
    "\n",
    "    return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(t, dim):\n",
    "    half_dim = dim // 2\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -(torch.log(torch.tensor(10000.0)) / half_dim))\n",
    "    emb = t.float()[:, None] * emb[None, :]\n",
    "    return torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes, ch, out_ch, ch_mult=(1, 2, 4, 8), num_res_blocks=2, attn_resolutions=[], dropout=0.0, resamp_with_conv=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.ch = ch\n",
    "        self.out_ch = out_ch\n",
    "        self.ch_mult = ch_mult\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.attn_resolutions = attn_resolutions\n",
    "        self.dropout = dropout\n",
    "        self.resamp_with_conv = resamp_with_conv\n",
    "\n",
    "        self.temb_dense_0 = dense\n",
    "        self.temb_dense_1 = dense\n",
    "\n",
    "        self.conv_in = weight_norm(nn.Conv2d(3, ch, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.down = nn.ModuleList()\n",
    "        self.up = nn.ModuleList()\n",
    "        num_resolutions = len(ch_mult)\n",
    "\n",
    "        for i_level in range(num_resolutions):\n",
    "            for i_block in range(num_res_blocks):\n",
    "                self.down.append(resnet_block)\n",
    "                if 2 ** i_level in attn_resolutions:\n",
    "                    self.down.append(attn_block)\n",
    "            if i_level != num_resolutions - 1:\n",
    "                self.down.append(downsample)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            resnet_block,\n",
    "            attn_block,\n",
    "            resnet_block,\n",
    "        ])\n",
    "\n",
    "        for i_level in reversed(range(num_resolutions)):\n",
    "            for i_block in range(num_res_blocks + 1):\n",
    "                self.up.append(resnet_block)\n",
    "                if 2 ** i_level in attn_resolutions:\n",
    "                    self.up.append(attn_block)\n",
    "            if i_level != 0:\n",
    "                self.up.append(upsample)\n",
    "\n",
    "        self.norm_out = normalize\n",
    "        self.conv_out = weight_norm(nn.Conv2d(ch, out_ch, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "    def forward(self, x, t, y=None):\n",
    "        B, C, H, W = x.shape\n",
    "        assert y is None, 'not supported'\n",
    "\n",
    "        temb = get_timestep_embedding(t, self.ch)\n",
    "        temb = self.temb_dense_0(temb, self.ch * 4)\n",
    "        temb = self.temb_dense_1(nonlinearity(temb), self.ch * 4)\n",
    "\n",
    "        h = self.conv_in(x)\n",
    "        hs = [h]\n",
    "\n",
    "        for layer in self.down:\n",
    "            h = layer(h, temb=temb)\n",
    "            hs.append(h)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            h = layer(h, temb=temb)\n",
    "\n",
    "        for layer in self.up:\n",
    "            h = layer(torch.cat([h, hs.pop()], dim=1), temb=temb)\n",
    "\n",
    "        h = nonlinearity(self.norm_out(h, temb=temb, name='norm_out'))\n",
    "        h = self.conv_out(h)\n",
    "        return h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
