{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinearity(x):\n",
    "    return F.silu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, temb, name):\n",
    "    return nn.GroupNorm(num_groups=32, num_channels=x.shape[1], eps=1e-6, affine=True)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, num_units, kernel_size=3, stride=1, init_scale=1.0):\n",
    "    conv = weight_norm(nn.Conv2d(x.shape[1], num_units, kernel_size, stride, padding=kernel_size // 2))\n",
    "    nn.init.kaiming_normal_(conv.weight, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "    conv.weight.data *= init_scale\n",
    "    return conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(x, with_conv):\n",
    "    B, C, H, W = x.shape\n",
    "    x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "    if with_conv:\n",
    "        x = conv2d(x, num_units=C, kernel_size=3, stride=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(x, with_conv):\n",
    "    if with_conv:\n",
    "        x = conv2d(x, num_units=x.shape[1], kernel_size=3, stride=2)\n",
    "    else:\n",
    "        x = F.avg_pool2d(x, kernel_size=2, stride=2, padding=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin(x, num_units):\n",
    "    B, C, H, W = x.shape\n",
    "    return weight_norm(nn.Conv2d(C, num_units, kernel_size=1, stride=1, padding=0))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(x, temb, out_ch=None, conv_shortcut=False, dropout=0.0):\n",
    "    B, C, H, W = x.shape\n",
    "    if out_ch is None:\n",
    "        out_ch = C\n",
    "\n",
    "    h = x\n",
    "    h = nonlinearity(normalize(h, temb, name='norm1'))\n",
    "    h = conv2d(h, num_units=out_ch)\n",
    "    h = h + nn.linear(nonlinearity(temb), out_ch)[:, :, None, None]\n",
    "\n",
    "    h = nonlinearity(normalize(h, temb, name='norm2'))\n",
    "    h = F.dropout(h, p=dropout, training=True)\n",
    "    h = conv2d(h, num_units=out_ch, init_scale=0.)\n",
    "\n",
    "    if C != out_ch:\n",
    "        if conv_shortcut:\n",
    "            x = conv2d(x, num_units=out_ch)\n",
    "        else:\n",
    "            x = nin(x, out_ch)\n",
    "\n",
    "    return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(x, num_units):\n",
    "    return weight_norm(nn.Linear(x.shape[-1], num_units))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_block(x, temb):\n",
    "    B, C, H, W = x.shape\n",
    "    h = normalize(x, temb=temb, name='norm')\n",
    "    q = nin(h, C)\n",
    "    k = nin(h, C)\n",
    "    v = nin(h, C)\n",
    "\n",
    "    w = torch.einsum('bchw,bCHW->bhwHW', q, k) * (C ** -0.5)\n",
    "    w = w.view(B, H, W, H * W)\n",
    "    w = F.softmax(w, dim=-1)\n",
    "    w = w.view(B, H, W, H, W)\n",
    "\n",
    "    h = torch.einsum('bhwHW,bHWc->bhwc', w, v)\n",
    "    h = nin(h, C)\n",
    "\n",
    "    return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(t, dim):\n",
    "    half_dim = dim // 2\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -(torch.log(torch.tensor(10000.0)) / half_dim))\n",
    "    emb = t.float()[:, None] * emb[None, :]\n",
    "    return torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes, ch, out_ch, ch_mult=(1, 2, 4, 8), num_res_blocks=2, attn_resolutions=[], dropout=0.0, resamp_with_conv=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.ch = ch\n",
    "        self.out_ch = out_ch\n",
    "        self.ch_mult = ch_mult\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.attn_resolutions = attn_resolutions\n",
    "        self.dropout = dropout\n",
    "        self.resamp_with_conv = resamp_with_conv\n",
    "\n",
    "        self.temb_dense_0 = dense\n",
    "        self.temb_dense_1 = dense\n",
    "\n",
    "        self.conv_in = weight_norm(nn.Conv2d(3, ch, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.down = nn.ModuleList()\n",
    "        self.up = nn.ModuleList()\n",
    "        num_resolutions = len(ch_mult)\n",
    "\n",
    "        for i_level in range(num_resolutions):\n",
    "            for i_block in range(num_res_blocks):\n",
    "                self.down.append(resnet_block)\n",
    "                if 2 ** i_level in attn_resolutions:\n",
    "                    self.down.append(attn_block)\n",
    "            if i_level != num_resolutions - 1:\n",
    "                self.down.append(downsample)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            resnet_block,\n",
    "            attn_block,\n",
    "            resnet_block,\n",
    "        ])\n",
    "\n",
    "        for i_level in reversed(range(num_resolutions)):\n",
    "            for i_block in range(num_res_blocks + 1):\n",
    "                self.up.append(resnet_block)\n",
    "                if 2 ** i_level in attn_resolutions:\n",
    "                    self.up.append(attn_block)\n",
    "            if i_level != 0:\n",
    "                self.up.append(upsample)\n",
    "\n",
    "        self.norm_out = normalize\n",
    "        self.conv_out = weight_norm(nn.Conv2d(ch, out_ch, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "    def forward(self, x, t, y=None):\n",
    "        B, C, H, W = x.shape\n",
    "        assert y is None, 'not supported'\n",
    "\n",
    "        temb = get_timestep_embedding(t, self.ch)\n",
    "        temb = self.temb_dense_0(temb, self.ch * 4)\n",
    "        temb = self.temb_dense_1(nonlinearity(temb), self.ch * 4)\n",
    "\n",
    "        h = self.conv_in(x)\n",
    "        hs = [h]\n",
    "\n",
    "        for layer in self.down:\n",
    "            h = layer(h, temb=temb)\n",
    "            \n",
    "            hs.append(h)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            h = layer(h, temb=temb)\n",
    "\n",
    "        for layer in self.up:\n",
    "            h = layer(torch.cat([h, hs.pop()], dim=1), temb=temb)\n",
    "\n",
    "        h = nonlinearity(self.norm_out(h, temb=temb, name='norm_out'))\n",
    "        h = self.conv_out(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='../../dataset', train=True, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fire'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfire\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fire'"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "import fire\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from diffusion_pytorch import utils\n",
    "from diffusion_pytorch.diffusion_utils_2 import get_beta_schedule, GaussianDiffusion2\n",
    "from diffusion_pytorch.models import unet\n",
    "from diffusion_pytorch.tpu_utils import tpu_utils, datasets, simple_eval_worker\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, *, model_name, betas, model_mean_type: str, model_var_type: str, loss_type: str,\n",
    "                 num_classes: int, dropout: float, randflip):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.diffusion = GaussianDiffusion2(\n",
    "            betas=betas, model_mean_type=model_mean_type, model_var_type=model_var_type, loss_type=loss_type)\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.randflip = randflip\n",
    "\n",
    "    def _denoise(self, x, t, y, dropout):\n",
    "        B, C, H, W = x.shape\n",
    "        assert x.dtype == torch.float32\n",
    "        assert t.shape == (B,) and t.dtype in [torch.int32, torch.int64]\n",
    "        assert y.shape == (B,) and y.dtype in [torch.int32, torch.int64]\n",
    "        out_ch = (C * 2) if self.diffusion.model_var_type == 'learned' else C\n",
    "        y = None\n",
    "        if self.model_name == 'unet2d16b2':  # 35.7M\n",
    "            return unet.model(\n",
    "                x, t=t, y=y, name='model', ch=128, ch_mult=(1, 2, 2, 2), num_res_blocks=2, attn_resolutions=(16,),\n",
    "                out_ch=out_ch, num_classes=self.num_classes, dropout=dropout\n",
    "            )\n",
    "        raise NotImplementedError(self.model_name)\n",
    "\n",
    "    def train_fn(self, x, y):\n",
    "        B, C, H, W = x.shape\n",
    "        if self.randflip:\n",
    "            x = torch.flip(x, dims=[-1])  # Random horizontal flip\n",
    "            assert x.shape == (B, C, H, W)\n",
    "        t = torch.randint(0, self.diffusion.num_timesteps, (B,), dtype=torch.int32, device=x.device)\n",
    "        losses = self.diffusion.training_losses(\n",
    "            denoise_fn=functools.partial(self._denoise, y=y, dropout=self.dropout), x_start=x, t=t)\n",
    "        assert losses.shape == t.shape == (B,)\n",
    "        return {'loss': losses.mean()}\n",
    "\n",
    "    def samples_fn(self, dummy_noise, y):\n",
    "        return {\n",
    "            'samples': self.diffusion.p_sample_loop(\n",
    "                denoise_fn=functools.partial(self._denoise, y=y, dropout=0),\n",
    "                shape=dummy_noise.shape,\n",
    "                noise_fn=torch.randn\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def progressive_samples_fn(self, dummy_noise, y):\n",
    "        samples, progressive_samples = self.diffusion.p_sample_loop_progressive(\n",
    "            denoise_fn=functools.partial(self._denoise, y=y, dropout=0),\n",
    "            shape=dummy_noise.shape,\n",
    "            noise_fn=torch.randn\n",
    "        )\n",
    "        return {'samples': samples, 'progressive_samples': progressive_samples}\n",
    "\n",
    "    def bpd_fn(self, x, y):\n",
    "        total_bpd_b, terms_bpd_bt, prior_bpd_b, mse_bt = self.diffusion.calc_bpd_loop(\n",
    "            denoise_fn=functools.partial(self._denoise, y=y, dropout=0),\n",
    "            x_start=x\n",
    "        )\n",
    "        return {\n",
    "            'total_bpd': total_bpd_b,\n",
    "            'terms_bpd': terms_bpd_bt,\n",
    "            'prior_bpd': prior_bpd_b,\n",
    "            'mse': mse_bt\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
