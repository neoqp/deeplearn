{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A->a B->?, Let's guess '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['propaganda', 'is', 'a', 'concerted', 'set', 'of', 'messages', 'aimed', 'at', 'influencing']\n"
     ]
    }
   ],
   "source": [
    "with open('../../dataset/NLP/tokens_wiki.txt', encoding='UTF-8') as f:\n",
    "    token = f.read()\n",
    "    \n",
    "token = token.split()\n",
    "print(token[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 시퀀스 만들기\n",
    "def generate_sorted_words(tokens):\n",
    "    counter = Counter(tokens)\n",
    "    l = []\n",
    "    for (word, cnt) in counter.most_common():\n",
    "        l.append(word)\n",
    "    return l\n",
    "\n",
    "def generate_word2code(sorted_words): \n",
    "    d = {}\n",
    "    for idx, word in enumerate(sorted_words):\n",
    "        d[word] = idx\n",
    "    return d\n",
    "\n",
    "def convert_tokens_to_codes(tokens, word2code):\n",
    "    return [word2code[word] for word in tokens]\n",
    "    \n",
    "\n",
    "# 시퀀스 기반으로 word-context 만들기\n",
    "def generate_word_by_context(\n",
    "    codes,                    # 시퀀스 (정수)\n",
    "    max_vocab_words = 1000,   # 중심어 가능 코드 (정수코드 최댓값, 행)\n",
    "    max_context_words = 1000, # 스캔 가능 코드 (정수코드 최댓값, 열)\n",
    "    context_size = 2,         # 좌우 단어 개수\n",
    "    weight_by_distance = True # 거리 고려 유무\n",
    "):\n",
    "    context = [[0 for _ in range(max_context_words)] for _ in range(max_vocab_words)]\n",
    "    for idx, number in enumerate(codes):\n",
    "        if number >= max_vocab_words:\n",
    "            continue\n",
    "        left = max(0, idx-context_size)\n",
    "        right = min(len(codes)-1, idx+context_size)\n",
    "        for i in range(left, right+1):\n",
    "            if i == idx:\n",
    "                continue\n",
    "            if codes[i] >= max_context_words:\n",
    "                continue\n",
    "            if weight_by_distance:\n",
    "                context[number][codes[i]] += 1 / abs(idx-i)\n",
    "            else:\n",
    "                context[number][codes[i]] += 1\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817.0 95654.0 113597.5 182741.5 48399.0 81480.5 52766.0 473.0 19117.5 18314.5 \n",
      "95654.0 52289.0 12922.5 21330.5 90439.5 33511.0 12738.5 25232.5 12492.5 16409.5 \n",
      "113597.5 12922.5 903.0 15554.0 11913.5 39034.0 7593.5 13774.0 8966.5 7202.0 \n",
      "182741.5 21330.5 15554.0 3885.0 13247.0 6934.0 2828.0 26331.5 3773.0 4003.5 \n",
      "48399.0 90439.5 11913.5 13247.0 2346.0 10864.0 7328.0 9792.0 4829.5 2812.0 \n",
      "81480.5 33511.0 39034.0 6934.0 10864.0 3162.0 5623.0 13171.0 3979.0 2386.0 \n",
      "52766.0 12738.5 7593.5 2828.0 7328.0 5623.0 3114.0 12138.0 5162.5 3338.0 \n",
      "473.0 25232.5 13774.0 26331.5 9792.0 13171.0 12138.0 154.0 11593.5 15802.0 \n",
      "19117.5 12492.5 8966.5 3773.0 4829.5 3979.0 5162.5 11593.5 123.0 1798.0 \n",
      "18314.5 16409.5 7202.0 4003.5 2812.0 2386.0 3338.0 15802.0 1798.0 7282.0 \n"
     ]
    }
   ],
   "source": [
    "sorted_word = generate_sorted_words(token)\n",
    "word2code = generate_word2code(sorted_word)\n",
    "codes = convert_tokens_to_codes(token, word2code)\n",
    "context = generate_word_by_context(codes)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        print(context[i][j], end=' ')\n",
    "    print('')\n",
    "    \n",
    "# print(token[:10])\n",
    "# print(codes[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
